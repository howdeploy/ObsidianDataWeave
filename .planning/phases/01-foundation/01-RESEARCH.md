# Phase 1: Foundation - Research

**Researched:** 2026-02-25
**Domain:** Python .docx parsing pipeline, rclone fetch, TOML/YAML config, rules distillation
**Confidence:** HIGH (verified by hands-on testing with actual project files and live tool execution)

---

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions

#### JSON Parser Output
- Inline formatting preserved as markdown (**bold**, *italic*, [links](url))
- Images marked as `[image]` placeholders in text flow
- Tables and lists handling ‚Äî Claude's discretion (markdown or structured JSON)
- Heading granularity for sections ‚Äî Claude's discretion (optimize for atomization input)

#### Tag Taxonomy
- Language: English tags only (`#tech/ai`, not `#—Ç–µ—Ö/–∏–∏`) ‚Äî universal for GitHub package
- Hierarchy: Nested tags using `/` separator (`#tech/ai`, `#tech/python`, `#productivity/pkm`)
- Broad spectrum: tech, productivity, science, personal, creative, business, health
- Auto-expansion: Claude can add new tags to tags.yaml when nothing fits ‚Äî no strict lock
- Starter taxonomy: ~30-50 tags covering wide range of research topics

#### Rules Distillation
- File structure ‚Äî Claude's discretion (one file or modular by aspect)
- Must include few-shot examples of good atomic notes alongside rules
- Rules language: English (better for LLM instruction following)
- Examples can be bilingual (EN rules, RU examples from actual content)
- Source: two .docx files in project root, distilled into rules/*.md

### Claude's Discretion
- JSON output schema design (fields, nesting)
- Section granularity (H2 vs H3 as split boundary)
- Tables/lists representation format
- Rules file organization (single vs modular)

### Deferred Ideas (OUT OF SCOPE)
- README language switcher (RU/EN button) ‚Äî Phase 4: Publish
- Bilingual README ‚Äî Phase 4: Publish
</user_constraints>

---

<phase_requirements>
## Phase Requirements

| ID | Description | Research Support |
|----|-------------|-----------------|
| CONF-01 | config.toml contains: vault_path, note folders, rclone remote | TOML config schema designed; tomllib (stdlib Python 3.11+) handles reading; write config.example.toml as template |
| CONF-02 | tags.yaml contains canonical tag taxonomy | YAML structure designed; PyYAML 6.0.3 already installed; 30-50 tags organized by domain |
| CONF-03 | config.example.toml shipped as template with no real paths | Pattern: commit config.example.toml to git; add config.toml to .gitignore |
| RULE-01 | Rules loaded from rules/*.md files, distilled from reference .docx | Both .docx files inspected and parsed; content extracted; rules/*.md structure decided |
| RULE-02 | Claude follows loaded rules during atomization, tagging, linking | Rules format designed as direct Claude operating instructions in English |
| RULE-03 | Two reference .docx files processed and converted to rules | Both files are in project root, successfully parsed; content fully readable |
| DOCX-01 | Skill downloads .docx from Google Drive by filename via rclone | rclone v1.73.0 installed; `gdrive:` remote works; `rclone copyto` handles Cyrillic+colon filenames |
| DOCX-02 | Parser extracts text preserving H1/H2/H3 hierarchy, lists, tables | python-docx 1.2.0 confirmed working on Python 3.14.2; style.name-based heading detection validated |
| DOCX-03 | Document split into sections by headings as atomization input units | Section splitting logic tested; actual docs use H3/H4 as top-level headings (not H1/H2) |
</phase_requirements>

---

## Summary

Phase 1 delivers the foundation all other phases build on: a locked config schema, a working fetch+parse pipeline, and distilled methodology rules. All three components are well-understood with no significant ambiguity.

**Critical discovery from hands-on testing:** Both reference .docx files (`Smart Connections` and `–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –í—Ç–æ—Ä–æ–≥–æ –º–æ–∑–≥–∞`) are already present in the project root. They were successfully parsed with python-docx 1.2.0. Importantly, both documents use `Heading 3` and `Heading 4` as their top-level headings ‚Äî not the conventional `Heading 1`/`Heading 2` pattern. The parser must handle arbitrary heading start levels. The section-splitting approach should detect the minimum heading level present and treat that as the top-level section boundary, then use relative depth for sub-sections.

The fetch pipeline is verified working end-to-end: rclone v1.73.0 with `gdrive:` remote successfully does dry-run copyto of both reference .docx files (including filenames with Cyrillic characters and colons). Python 3.14.2 is installed with `tomllib` built-in and PyYAML 6.0.3 pre-installed. python-docx 1.2.0 was installed during this research session and confirmed working.

**Primary recommendation:** Use python-docx for parsing (heading detection via `style.name` regex match on `Heading \d+`), tomllib for config, PyYAML for tags.yaml, and `rclone copyto` for fetching. All tools are confirmed working on this system. The rules distillation from the reference .docx content can be done directly ‚Äî the content was fully read during research and is ready for conversion to `rules/*.md`.

---

## Standard Stack

### Core

| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| python-docx | 1.2.0 | Parse .docx: extract paragraph styles, heading levels, runs (bold/italic), tables | Only Python library that preserves heading hierarchy via `paragraph.style.name`; gives direct access to document XML structure; no competing alternatives for structural extraction |
| PyYAML | 6.0.3 | Read/write tags.yaml and YAML frontmatter | Pre-installed on this system; `yaml.safe_load()` + `yaml.dump(allow_unicode=True)` handles Cyrillic correctly |
| tomllib | stdlib (Python 3.11+) | Read config.toml | Built into Python 3.14.2 (this system); zero install required; TOML is human-editable and supports comments unlike JSON |
| rclone | v1.73.0 | Fetch .docx files from Google Drive | Already configured with `gdrive:` remote; handles Cyrillic+colon filenames correctly; `rclone copyto` exits with code 3 on file-not-found |
| subprocess (stdlib) | stdlib | Call rclone from Python | `subprocess.run(["rclone", "copyto", src, dst], check=True, capture_output=True)` ‚Äî secure, no shell injection |

### Supporting

| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| pathlib (stdlib) | stdlib | Path manipulation for staging dir, config paths | Always ‚Äî handles `/tmp/dw/staging/` and vault paths with spaces cleanly |
| re (stdlib) | stdlib | Heading style name detection, runs-to-markdown conversion | Always ‚Äî `re.match(r'Heading (\d+)', style.name, re.IGNORECASE)` |
| json (stdlib) | stdlib | Write structured JSON output from parser | Always ‚Äî `json.dumps(result, ensure_ascii=False, indent=2)` |
| hashlib (stdlib) | stdlib | Content hashing for idempotency (Phase 3, but schema defined here) | Phase 3 vault writer, but hash field included in JSON schema now |

### Alternatives Considered

| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| python-docx | mammoth | mammoth converts to HTML/markdown but loses heading style metadata ‚Äî can't distinguish H1 from H2 from body text without it |
| python-docx | pandoc (subprocess) | Pandoc adds a system dependency and produces markdown that needs post-processing; python-docx gives direct API access |
| tomllib (read-only) | tomlkit | tomlkit supports read+write TOML; not needed because config.toml is hand-written by user, not auto-generated by scripts |
| PyYAML | ruamel.yaml | ruamel.yaml preserves comments in round-trips; not needed since tags.yaml is written once and rarely modified programmatically |

**Installation:**
```bash
# python-docx is the only non-stdlib, non-pre-installed dependency for Phase 1
python3 -m pip install python-docx --break-system-packages
# OR for install.sh: use --user flag to avoid system packages issue
python3 -m pip install python-docx --user

# Already installed on this system:
# PyYAML 6.0.3 (pre-installed on Manjaro)
# tomllib (built into Python 3.14.2)
```

**Note on lxml:** python-docx depends on lxml. Confirmed it installed cleanly via pip on Python 3.14.2 without requiring `pacman -S python-lxml`. No system package prerequisite needed.

---

## Architecture Patterns

### Recommended Project Structure

```
ObsidianDataWeave/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ fetch_docx.sh          # rclone copyto gdrive:"{name}" /tmp/dw/staging/
‚îÇ   ‚îî‚îÄ‚îÄ parse_docx.py          # .docx ‚Üí structured JSON (stdout or file)
‚îú‚îÄ‚îÄ rules/
‚îÇ   ‚îú‚îÄ‚îÄ atomization.md         # Atomic note rules + few-shot examples
‚îÇ   ‚îî‚îÄ‚îÄ taxonomy.md            # Tag usage rules + MOC/Zettelkasten patterns
‚îú‚îÄ‚îÄ config.toml                # User's real config (gitignored)
‚îú‚îÄ‚îÄ config.example.toml        # Template with placeholder values (committed)
‚îú‚îÄ‚îÄ tags.yaml                  # Canonical tag taxonomy (committed)
‚îî‚îÄ‚îÄ .gitignore                 # Includes config.toml
```

Phase 1 delivers: `scripts/`, `rules/`, `config.example.toml`, `tags.yaml`, `.gitignore`. The `config.toml` is created by the user from the example.

### Pattern 1: Heading-Aware Section Splitting

**What:** Walk document paragraphs; detect headings via `paragraph.style.name` matching `Heading \d+`; group subsequent paragraphs under their nearest heading parent.

**Critical finding:** Both reference .docx files use `Heading 3` and `Heading 4` as their top-level headings (not `Heading 1`/`Heading 2`). NotebookLM exports from Google Docs can start at any heading level. The parser must be level-agnostic: detect the minimum heading level in the document and treat it as depth 1 for output purposes.

**When to use:** Always for structured .docx parsing.

**Example (verified working on actual project files):**
```python
import docx, re, json

def get_heading_level(para):
    """Returns int heading level (1-9) or None for non-heading paragraphs."""
    m = re.match(r'Heading (\d+)', para.style.name, re.IGNORECASE)
    return int(m.group(1)) if m else None

def runs_to_markdown(para):
    """Convert runs with bold/italic marks to markdown inline formatting."""
    parts = []
    for run in para.runs:
        text = run.text
        if not text:
            continue
        if run.bold and run.italic:
            text = f'***{text}***'
        elif run.bold:
            text = f'**{text}**'
        elif run.italic:
            text = f'*{text}*'
        parts.append(text)
    return ''.join(parts)

def parse_docx_to_json(path: str) -> dict:
    doc = docx.Document(path)

    # Determine heading start level (may be H3/H4, not H1/H2)
    heading_levels = [
        get_heading_level(p) for p in doc.paragraphs
        if get_heading_level(p) is not None
    ]
    min_level = min(heading_levels) if heading_levels else 1

    result = {
        "source_file": path.split("/")[-1],
        "heading_depth_offset": min_level - 1,  # normalize to H1 for consumers
        "sections": []
    }
    current_section = None

    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            continue
        level = get_heading_level(para)
        if level is not None:
            current_section = {
                "heading": text,
                "level": level - (min_level - 1),  # normalize: min_level -> 1
                "paragraphs": []
            }
            result["sections"].append(current_section)
        else:
            content = runs_to_markdown(para)
            if current_section is None:
                current_section = {"heading": None, "level": 0, "paragraphs": []}
                result["sections"].append(current_section)
            current_section["paragraphs"].append(content)

    return result

if __name__ == "__main__":
    import sys
    data = parse_docx_to_json(sys.argv[1])
    print(json.dumps(data, ensure_ascii=False, indent=2))
```

### Pattern 2: rclone Fetch with Error Handling

**What:** Use `rclone copyto` to download a named file from Google Drive root to local staging dir. Check exit code; exit code 3 = file not found.

**When to use:** Always for Google Drive fetching ‚Äî do not re-implement Drive API auth.

**Example:**
```bash
#!/usr/bin/env bash
set -euo pipefail

FILENAME="${1:?Usage: fetch_docx.sh <filename>}"
STAGING_DIR="${2:-/tmp/dw/staging}"

mkdir -p "${STAGING_DIR}"

# Build source path (rclone reads from config's gdrive: remote)
SOURCE="gdrive:${FILENAME}"
DEST="${STAGING_DIR}/${FILENAME}"

echo "Fetching: ${FILENAME}"
if rclone copyto "${SOURCE}" "${DEST}" 2>&1; then
    echo "Downloaded to: ${DEST}"
    echo "${DEST}"  # stdout: local path for caller
else
    EXIT_CODE=$?
    if [ "${EXIT_CODE}" -eq 3 ]; then
        echo "ERROR: File not found on Google Drive: ${FILENAME}" >&2
        echo "Available .docx files:" >&2
        rclone lsf "gdrive:" --max-depth 1 --include "*.docx" >&2
    else
        echo "ERROR: rclone failed with exit code ${EXIT_CODE}" >&2
    fi
    exit "${EXIT_CODE}"
fi
```

### Pattern 3: TOML Config Loading

**What:** Read config.toml with tomllib (Python 3.11+ stdlib). Config is read-only by scripts ‚Äî users hand-edit it.

**When to use:** At the start of every script that needs vault path, rclone remote, or staging dir.

**Example:**
```python
import tomllib
from pathlib import Path

DEFAULT_CONFIG_PATH = Path.home() / ".config" / "obsidian-dataweave" / "config.toml"
LOCAL_CONFIG_PATH = Path("config.toml")

def load_config(config_path: Path = None) -> dict:
    path = config_path or (LOCAL_CONFIG_PATH if LOCAL_CONFIG_PATH.exists() else DEFAULT_CONFIG_PATH)
    with open(path, "rb") as f:  # tomllib requires binary mode
        config = tomllib.load(f)
    # Validate required fields
    required = [("vault", "vault_path"), ("rclone", "remote")]
    for section, key in required:
        if section not in config or key not in config[section]:
            raise ValueError(f"Missing required config: [{section}] {key}")
    return config
```

### Pattern 4: tags.yaml Nested Structure

**What:** Organize tags hierarchically under domain categories. Flat list of `domain/subtag` strings under each category. Load at runtime to constrain tag selection.

**When to use:** tags.yaml is the single source of truth for all tag assignments in Phase 2+.

**Example structure:**
```yaml
# tags.yaml
version: 1
# Tags use / for hierarchy: tech/ai appears as #tech/ai in Obsidian
# Claude may propose new tags but must log them to proposed-tags.md
tags:
  tech:
    - ai
    - llm
    - python
    - javascript
    - devops
    - security
    - data
    - tools
    - automation
  productivity:
    - pkm
    - notetaking
    - gtd
    - workflow
    - obsidian
    - zettelkasten
    - moc
  science:
    - neuroscience
    - biology
    - physics
    - mathematics
    - research-methods
  personal:
    - health
    - learning
    - finance
    - relationships
  creative:
    - writing
    - design
    - content
  business:
    - startup
    - marketing
    - strategy
    - management
  philosophy:
    - epistemology
    - ethics
    - cognition
```

### Pattern 5: Rules File Structure for Claude Consumption

**What:** Rules files are written as direct operating instructions in English, structured so Claude can load them into context and immediately follow them. Include few-shot examples with bilingual examples (EN rule, RU example).

**When to use:** The two reference .docx files have been fully read. Their content divides cleanly into:
1. `rules/atomization.md` ‚Äî atomic note principles (1 idea = 1 note, 150-600 words, noun-phrase titles)
2. `rules/taxonomy.md` ‚Äî tag usage, MOC structure, wikilink rules, YAML frontmatter schema

**Example rule format:**
```markdown
# Atomization Rules

## Core Principle
One note = one idea that can stand alone without reading any other note.

## Constraints
- Length: 150-600 words per atomic note
- Title: noun phrase, not full sentence ("Zettelkasten link types" not "How Zettelkasten links work")
- Focus: one claim, one concept, one technique

## Few-Shot Examples

### Good atomic note (RU example from reference docs)
**Title:** –í–µ–∫—Ç–æ—Ä–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ Smart Connections
**Content:** Smart Connections –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞...
**Why good:** Single concept (vector embeddings), self-contained, ~200 words

### Bad: too broad
**Title:** Smart Connections –ø–ª–∞–≥–∏–Ω (would be 2000+ words covering everything)
**Fix:** Split into: embeddings, chat interface, installation, best practices
```

### Anti-Patterns to Avoid

- **Splitting on every paragraph:** Paragraphs are not atomic ideas. Split on heading boundaries first; let Phase 2 Claude decide sub-splits within sections.
- **Assuming Heading 1 is the top level:** These specific .docx files use Heading 3 as their top level. Always detect `min(heading_levels)` dynamically.
- **Hardcoding `gdrive:` remote name in scripts:** Read it from config.toml `[rclone] remote` field so other users with differently named remotes can use the tool.
- **Writing config.toml to git:** config.toml contains the user's real vault path. Always gitignore it; commit only config.example.toml.
- **Using `shell=True` in subprocess rclone calls:** Filenames contain spaces and Cyrillic ‚Äî shell=True risks injection. Use list form: `["rclone", "copyto", source, dest]`.

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| .docx parsing | Custom XML parser for .docx zip | python-docx | .docx is complex Office Open XML; python-docx handles styles, runs, embedded images, tables, namespace resolution |
| Google Drive auth | OAuth flow, token refresh, Drive API client | rclone (already configured) | rclone handles auth, retry, partial downloads, multiple remotes; reimplementing is weeks of work |
| TOML parsing | Custom key=value parser | tomllib (stdlib) | TOML has multiline strings, dates, arrays, tables ‚Äî custom parsers always miss edge cases |
| YAML tag loading | Manual YAML parser | PyYAML `yaml.safe_load()` | YAML has anchors, aliases, multi-document streams ‚Äî custom parsers break on edge cases |
| Heading detection | String prefix matching ("# Heading") | python-docx `paragraph.style.name` | .docx headings are style-based, not markdown-style. Prefix matching would miss any heading that doesn't happen to start with a hash |

**Key insight:** The .docx format is a ZIP archive containing complex XML with namespace declarations. python-docx is the result of years of reverse-engineering Office Open XML ‚Äî treating it as "just XML" leads to missed content, encoding bugs, and namespace errors.

---

## Common Pitfalls

### Pitfall 1: Assuming Standard Heading Levels

**What goes wrong:** Code assumes headings start at `Heading 1` and splits sections on H1/H2. Both reference .docx files use `Heading 3` and `Heading 4` as their top-level structural elements. A hardcoded H1/H2 split produces zero sections.

**Why it happens:** The .docx files were likely generated from Google Docs or NotebookLM, which may use non-standard heading numbering. Heading level choice in Google Docs is visual, not semantic.

**How to avoid:** Always compute `min_level = min(get_heading_level(p) for p in doc.paragraphs if heading)` and use it as the normalization base. Top-level sections are defined by `min_level`, not hardcoded as `Heading 1`.

**Warning signs:** `parse_docx.py` output has 0 or 1 sections from a document you can see has multiple headings in Word/Docs.

### Pitfall 2: rclone Filename with Colons and Cyrillic

**What goes wrong:** Script fails to fetch `–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –í—Ç–æ—Ä–æ–≥–æ –º–æ–∑–≥–∞: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è Obsidian –∏ Claude MCP.docx` because the colon in the filename causes path confusion.

**Why it happens:** Colons are path separators in some contexts; Cyrillic characters require UTF-8 handling.

**How to avoid:** rclone handles this correctly when using list-form subprocess (not shell=True). Verified in dry-run: `rclone copyto "gdrive:Smart Connections: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –º–æ–∑–≥ –≤–∞—à–µ–π –±–∞–∑—ã Obsidian.docx" /tmp/test.docx` exits 0. Do not double-quote the filename inside the list ‚Äî pass it as a Python string in the list.

**Warning signs:** `exit code 3: directory not found` when the file clearly exists in Drive.

### Pitfall 3: tomllib Requires Binary Mode

**What goes wrong:** `open(config_path, "r")` fails with `tomllib.load()`. tomllib requires binary file mode.

**Why it happens:** tomllib (unlike tomlkit) requires `"rb"` not `"r"` ‚Äî it handles UTF-8 decoding internally.

**How to avoid:** Always `open(path, "rb")` for tomllib.

**Warning signs:** `TypeError: a bytes-like object is required` from tomllib.load().

### Pitfall 4: PyYAML `yaml.load()` without safe_load

**What goes wrong:** Using `yaml.load(data)` triggers a security warning or loads arbitrary Python objects.

**Why it happens:** `yaml.load()` without a Loader is deprecated and unsafe for untrusted input.

**How to avoid:** Always use `yaml.safe_load(data)` for reading. For writing, use `yaml.dump(data, allow_unicode=True, default_flow_style=False)`.

**Warning signs:** PyYAML emits `YAMLLoadWarning: calling yaml.load() without Loader=...`.

### Pitfall 5: config.toml Committed to Git with Real Paths

**What goes wrong:** User's vault path `/mnt/sda1/KISA's Space/` and rclone remote name appear in git history and on GitHub.

**Why it happens:** Developer commits working config to test quickly, forgets to gitignore before publishing.

**How to avoid:** Add `config.toml` to `.gitignore` in this phase (before any config is written). Commit only `config.example.toml` with placeholder values. Make `.gitignore` the first file committed.

**Warning signs:** `git status` shows `config.toml` as tracked. `git log --all -- config.toml` shows it in history.

### Pitfall 6: Rules Files Too Verbose to Fit in Context

**What goes wrong:** Rules files are copies of the reference .docx content (2000+ words each) instead of distilled operating instructions. Phase 2 Claude prompt exceeds useful context density.

**Why it happens:** Easy to dump the content rather than distill it. The two reference .docx files together are ~4000 words.

**How to avoid:** Target each rules file at 400-600 words. Rules are principles + examples, not documentation. If a rule needs 200 words to explain, it's probably two rules.

**Warning signs:** `rules/atomization.md` is longer than 800 words.

---

## Code Examples

Verified patterns from hands-on testing with actual project files:

### Complete parse_docx.py Output Schema (verified)
```json
{
  "source_file": "Smart Connections: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –º–æ–∑–≥ –≤–∞—à–µ–π –±–∞–∑—ã Obsidian.docx",
  "heading_depth_offset": 2,
  "sections": [
    {
      "heading": null,
      "level": 0,
      "paragraphs": ["Intro paragraph before first heading..."]
    },
    {
      "heading": "üìÑ –ë—Ä–∏—Ñ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ README: –ü–ª–∞–≥–∏–Ω Smart Connections –¥–ª—è Obsidian",
      "level": 1,
      "paragraphs": []
    },
    {
      "heading": "1. –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–ß—Ç–æ —ç—Ç–æ –∏ –∑–∞—á–µ–º –Ω—É–∂–Ω–æ)",
      "level": 2,
      "paragraphs": [
        "**–ù–∞–∑–≤–∞–Ω–∏–µ:** Smart Connections.",
        "**–°—É—Ç—å:** –≠—Ç–æ –ø–ª–∞–≥–∏–Ω –¥–ª—è Obsidian, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–º–µ—Ç–æ–∫ –≤..."
      ]
    }
  ]
}
```

Note: `level` is normalized (H3 in source ‚Üí level 1 in output, H4 ‚Üí level 2). `heading_depth_offset: 2` means source used H3 as top-level.

### config.example.toml Schema (locked for Phase 1)
```toml
# ObsidianDataWeave Configuration
# Copy to config.toml and fill in your values

[vault]
vault_path = "/path/to/your/obsidian/vault"
notes_folder = "Research & Insights"       # atomic notes destination
moc_folder = "Guides & Overviews"          # MOC files destination
source_folder = "Sources"                   # source document references

[rclone]
remote = "gdrive:"                          # rclone remote name (check: rclone listremotes)
staging_dir = "/tmp/dw/staging"            # temporary staging area

[processing]
default_note_type = "atomic"               # frontmatter note_type default
```

### Verified rclone Commands
```bash
# Check available files (returns exit 0 even if no matches)
rclone lsf "gdrive:" --max-depth 1 --include "*.docx"

# List with metadata (JSON format for scripting)
rclone lsjson "gdrive:" --max-depth 1

# Download specific file (handles Cyrillic + colons correctly)
rclone copyto "gdrive:Filename With Spaces: And Colon.docx" "/tmp/dw/staging/output.docx"

# Verify file exists before downloading
rclone ls "gdrive:" --max-depth 1 --include "My File.docx"  # empty output = not found
```

### tags.yaml Loading Pattern
```python
import yaml
from pathlib import Path

def load_tags(tags_path: Path = Path("tags.yaml")) -> list[str]:
    """Load canonical tag taxonomy and return flat list of tag/subtag paths."""
    with open(tags_path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)
    tags = []
    for domain, subtags in data["tags"].items():
        for subtag in subtags:
            tags.append(f"{domain}/{subtag}")
    return tags
    # Returns: ["tech/ai", "tech/python", "productivity/pkm", ...]
```

---

## Key Discoveries from Research

### Discovery 1: Both Reference .docx Files Are Already Parsed

The reference .docx files (`Smart Connections` and `–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –í—Ç–æ—Ä–æ–≥–æ –º–æ–∑–≥–∞`) have been read in full during this research session. Their content is:

**Smart Connections** (27 paragraphs, styles: Heading 3, Heading 4, normal):
- Describes the Smart Connections plugin: vector embeddings, semantic search, sidebar recommendations
- Best practices: atomicity (1 note = 1 idea), own words, contextual indexing
- Business model: freemium, local AI support

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –í—Ç–æ—Ä–æ–≥–æ –º–æ–∑–≥–∞** (57 paragraphs, styles: Heading 3, normal):
- Part 1: Formatting rules ‚Äî strict Markdown, atomicity, one-source-one-note, interlinking, MOC usage, YAML frontmatter
- Part 2: Claude Code skill prompt for acting as Smart Connections replacement ‚Äî step-by-step instructions for linking, finding MOC hubs, semantic search, backlinks

These two documents together provide the complete rules corpus for `rules/atomization.md` and `rules/taxonomy.md`. Plan 01-03 (rules extraction) has the source material ready to distill.

### Discovery 2: Documents Use Non-Standard Heading Levels

Both documents are structured with H3 as top level and H4 for sub-sections. The DOCX-03 requirement says "split into sections by headings" ‚Äî the implementation must normalize these to logical levels (H3 ‚Üí Level 1, H4 ‚Üí Level 2) rather than emit raw heading numbers that would confuse Phase 2.

### Discovery 3: Python 3.14 + lxml Compatibility Confirmed

python-docx 1.2.0 installed and ran successfully on Python 3.14.2 without requiring system `python-lxml` from pacman. The install.sh in Phase 4 can use `pip install python-docx --user` without additional prerequisites.

---

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| `import tomli` (third-party) | `import tomllib` (stdlib) | Python 3.11 (Oct 2022) | Zero install for TOML parsing on Python 3.11+ |
| `yaml.load()` | `yaml.safe_load()` | PyYAML 5.1 (2019) | Security fix for YAML deserialization |
| `subprocess.call()` | `subprocess.run(..., check=True)` | Python 3.5 (2015) | Raises on non-zero exit; cleaner error handling |
| `os.path` | `pathlib.Path` | Python 3.6+ (2016) | Cleaner syntax; handles paths with spaces correctly |
| python-docx 0.8.x | python-docx 1.x | 2023 | Version 1.x dropped Python 2 support; 1.2.0 is current |

**Deprecated/outdated:**
- `docx2txt`: Strips all structure (no heading levels). Do not use.
- `textract`: Unmaintained since 2021, requires antiword/pdftotext C libraries. Do not use.
- `subprocess.call()`: Use `subprocess.run()` instead. `call()` doesn't raise on non-zero exit.

---

## Open Questions

1. **Tables and lists representation in JSON**
   - What we know: Both reference .docx files have 0 tables. Lists appear as `normal`-style paragraphs with list content (not as `List Paragraph` style).
   - What's unclear: Future user .docx files may have actual tables. python-docx `doc.tables` returns them separately from `doc.paragraphs`.
   - Recommendation (Claude's discretion per CONTEXT.md): Represent tables as markdown tables (`| col1 | col2 |`) inline in the paragraphs array. Lists detected heuristically (paragraphs starting with `‚Ä¢`, `-`, numbers) converted to markdown list syntax. Add a `"tables": []` field to the JSON schema at top level for any tables found.

2. **H2 vs H3 as section split boundary for user documents**
   - What we know: Reference docs use H3/H4. User's actual research documents from NotebookLM may use any heading level.
   - What's unclear: Whether user documents will follow the same pattern or use H1/H2.
   - Recommendation: The dynamic `min_level` detection handles this automatically. No configuration needed.

3. **Config location: project-local vs. `~/.config`**
   - What we know: Project is a Claude Code skill. The user runs it from the project directory.
   - What's unclear: Whether config should live in the project root (`./config.toml`) or at `~/.config/obsidian-dataweave/config.toml`.
   - Recommendation: Project-local `./config.toml` for Phase 1. This is simpler, easier to gitignore, and visible to the user. `~/.config/` location is a Phase 4 publish concern for portability.

---

## Sources

### Primary (HIGH confidence)

- Hands-on testing with actual project files ‚Äî python-docx 1.2.0 on Python 3.14.2 running both reference .docx files; rclone copyto dry-run with Cyrillic+colon filenames; tomllib and PyYAML verified on this system
- `/home/kosya/vibecoding/ObsidianDataWeave/.planning/research/STACK.md` ‚Äî prior stack research (MEDIUM confidence, web search unavailable when written; now upgraded to HIGH after hands-on verification)
- `/home/kosya/vibecoding/ObsidianDataWeave/.planning/research/ARCHITECTURE.md` ‚Äî prior architecture research (HIGH confidence)
- `/home/kosya/vibecoding/ObsidianDataWeave/.planning/research/PITFALLS.md` ‚Äî prior pitfall research (MEDIUM confidence)
- PyPI: python-docx 1.2.0 is the current release (verified via `pip index versions python-docx`)
- rclone v1.73.0 official behavior ‚Äî `copyto` exit codes, filename handling with spaces and Cyrillic, lsf/lsjson commands

### Secondary (MEDIUM confidence)

- python-docx API: `paragraph.style.name`, `paragraph.runs`, `run.bold`, `run.italic` ‚Äî verified against actual document parsing output
- PyYAML 6.0.3: `yaml.safe_load()` and `yaml.dump(allow_unicode=True)` ‚Äî standard usage, confirmed pre-installed
- tomllib: binary-mode requirement ‚Äî confirmed via Python 3.14.2 stdlib documentation

### Tertiary (LOW confidence, flagged for validation)

- word-count guardrails (150-600 words/note), wikilink density caps (3-7/note) ‚Äî heuristic guidelines from prior research; not empirically validated against user's actual NotebookLM exports; validate in Phase 2

---

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH ‚Äî all libraries installed and tested hands-on on this specific system
- Architecture: HIGH ‚Äî patterns verified by testing against actual project .docx files
- Pitfalls: HIGH for technical pitfalls (heading levels, rclone filenames, tomllib mode) ‚Äî discovered by running actual code; MEDIUM for methodology pitfalls (atomization thresholds) ‚Äî heuristic

**Research date:** 2026-02-25
**Valid until:** 2026-03-25 (stable ecosystem; python-docx and rclone APIs don't change frequently)

---

*Phase 1 Foundation research for ObsidianDataWeave*
*All technical findings verified by hands-on execution on the target system*
