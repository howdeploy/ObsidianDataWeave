---
phase: 02-ai-core
plan: "02"
type: execute
wave: 2
depends_on:
  - "02-01"
files_modified:
  - scripts/atomize.py
autonomous: true
requirements:
  - LINK-03
  - LINK-04
  - DOCX-04
  - DOCX-05
  - META-01
  - META-02
  - META-03
  - META-04
  - LINK-01
  - LINK-02

must_haves:
  truths:
    - "atomize.py accepts a parsed JSON file path and produces an atom plan JSON file in staging"
    - "atomize.py loads SKILL.md, rules/atomization.md, rules/taxonomy.md, and tags.yaml at runtime and assembles them into a single prompt for Claude"
    - "atomize.py validates the atom plan JSON output: required fields present, note_type valid, tag count 2-5, exactly 1 MOC"
    - "atomize.py creates proposed-tags.md in staging even when no new tags are proposed"
    - "atomize.py strips markdown code fences from Claude's JSON response before parsing"
    - "Wikilink consistency check ensures all [[Title]] references match actual note titles in the plan"
  artifacts:
    - path: "scripts/atomize.py"
      provides: "Python orchestrator that calls Claude with SKILL.md prompt and produces atom plan JSON"
      exports: ["main", "validate_atom_plan", "validate_tags", "validate_wikilinks"]
  key_links:
    - from: "scripts/atomize.py"
      to: "SKILL.md"
      via: "load_skill_md() reads SKILL.md content"
      pattern: "SKILL\\.md"
    - from: "scripts/atomize.py"
      to: "tags.yaml"
      via: "load_tags() reads and flattens tags.yaml"
      pattern: "tags\\.yaml"
    - from: "scripts/atomize.py"
      to: "rules/atomization.md"
      via: "load_rules() reads rules content"
      pattern: "atomization\\.md"
    - from: "scripts/atomize.py"
      to: "rules/taxonomy.md"
      via: "load_rules() reads rules content"
      pattern: "taxonomy\\.md"
    - from: "scripts/atomize.py"
      to: "/tmp/dw/staging/"
      via: "writes atom plan JSON and proposed-tags.md to staging directory"
      pattern: "staging"
---

<objective>
Create scripts/atomize.py — the Python orchestrator that loads SKILL.md + rules + tags + parsed JSON, assembles a complete prompt, calls Claude CLI, parses the response into atom plan JSON, validates it, and writes to staging. This is the executable bridge between Phase 1's parsed JSON and Phase 3's vault writer.

Purpose: atomize.py is the glue that makes SKILL.md actionable. It handles all the Python mechanics (file I/O, config reading, Claude CLI invocation, JSON parsing, validation, error handling) so SKILL.md stays pure instructions. Without atomize.py, SKILL.md is just a document.

Output: scripts/atomize.py (~200-250 lines Python), producing {docname}-atom-plan.json in staging and proposed-tags.md (always created).
</objective>

<execution_context>
@/home/kosya/.claude/get-shit-done/workflows/execute-plan.md
@/home/kosya/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ai-core/02-CONTEXT.md
@.planning/phases/02-ai-core/02-RESEARCH.md
@.planning/phases/02-ai-core/02-01-SUMMARY.md
@SKILL.md
@scripts/parse_docx.py
@tags.yaml
@config.example.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create atomize.py orchestrator with prompt assembly and Claude invocation</name>
  <files>scripts/atomize.py</files>
  <action>
Create scripts/atomize.py as a Python 3.11+ script. Use only stdlib + PyYAML (already installed). Structure:

**Imports and constants:**
```python
import json, yaml, sys, subprocess, argparse, re
from pathlib import Path
from datetime import date
import tomllib
```
PROJECT_ROOT = Path(__file__).parent.parent
REQUIRED_ATOM_FIELDS = {"id", "title", "note_type", "tags", "source_doc", "date", "body", "proposed_new_tags"}
VALID_NOTE_TYPES = {"atomic", "moc", "source"}

**Helper functions:**

1. `load_config() -> dict` — read config.toml via tomllib; fall back to {"rclone": {"staging_dir": "/tmp/dw/staging"}} if config.toml not found (with warning to stderr)

2. `load_tags(tags_path) -> list[str]` — yaml.safe_load tags.yaml, flatten to list of "domain/subtag" strings. Return sorted list.

3. `load_skill_md() -> str` — read SKILL.md from PROJECT_ROOT

4. `load_rules() -> tuple[str, str]` — read rules/atomization.md and rules/taxonomy.md, return as (atomization_text, taxonomy_text)

5. `assemble_prompt(parsed_json, tags, skill_md, atomization_rules, taxonomy_rules) -> str` — build the complete prompt:
   - Start with skill_md content
   - Append "---\n## Atomization Rules\n" + atomization_rules
   - Append "---\n## Taxonomy Rules\n" + taxonomy_rules
   - Append "---\n## Available Tags (from tags.yaml)\n" + bullet list of all tags
   - Append "---\n## Document to Process\n```json\n" + json.dumps(parsed_json, ensure_ascii=False, indent=2) + "\n```"
   - Append "\nProduce the complete atom plan JSON now. Output ONLY the JSON, no prose."

6. `call_claude(prompt: str) -> str` — call `["claude", "--print"]` via subprocess.run with input=prompt, capture_output=True, text=True, encoding="utf-8". Raise RuntimeError on non-zero exit code with stderr content. Return stdout.strip().

7. `extract_json(response: str) -> dict` — strip markdown code fences defensively:
   - If "```json" in response: extract between ```json and next ```
   - Elif "```" in response: extract between first ``` and next ```
   - Else: use response as-is
   - json.loads() and return dict. Raise ValueError with helpful message if JSON parsing fails.

**Validation functions:**

8. `validate_atom_plan(plan: dict) -> list[str]` — return list of error strings:
   - Check "notes" key exists
   - For each note: check all REQUIRED_ATOM_FIELDS present
   - For each note: check note_type in VALID_NOTE_TYPES
   - For each note: check 2 <= len(tags) <= 5
   - Check exactly 1 MOC note (note_type == "moc")
   - Check all note ids are unique

9. `validate_tags(plan: dict, valid_tags: set[str]) -> list[str]` — identify non-canonical tags:
   - For each note, for each tag: check if tag in valid_tags
   - Return list of warnings (not errors — Claude may have correctly placed tag in proposed_new_tags)

10. `validate_wikilinks(plan: dict) -> list[str]` — check wikilink consistency:
    - Collect all note titles into a set
    - For each note body, find all [[...]] patterns using regex: r'\[\[([^\]]+)\]\]'
    - For each wikilink target: check if it exists in the title set
    - Return list of errors for orphaned wikilinks

**Output functions:**

11. `write_proposed_tags(plan: dict, staging_dir: Path, source_file: str) -> None`:
    - ALWAYS create proposed-tags.md if it does not exist (with header: "# Proposed New Tags\n\nTags proposed by Claude not in tags.yaml. Review and add if appropriate.\n")
    - Collect proposed_tags from top-level plan field AND from each note's proposed_new_tags
    - If any proposed tags exist: append a dated section with source file name and each tag + reason
    - Important: always create the file even if empty — Phase 3 depends on it existing

**Main function:**

12. `main()`:
    - argparse: positional "input" (parsed JSON path), optional "-o"/"--output" (output path), optional "--dry-run" (print prompt, don't call Claude)
    - Load parsed JSON from input path
    - Load config, tags, skill_md, rules
    - Assemble prompt
    - If --dry-run: print prompt to stdout and exit 0
    - Call Claude, extract JSON from response
    - Validate atom plan (print errors to stderr; exit 1 if any validation errors)
    - Validate tags (print warnings to stderr; do NOT exit on tag warnings)
    - Validate wikilinks (print warnings to stderr; do NOT exit on wikilink warnings — Claude may use semantic links)
    - Determine output path: args.output or staging_dir / (input_stem + "-atom-plan.json")
    - Write atom plan JSON to output path (json.dumps with ensure_ascii=False, indent=2)
    - Write proposed-tags.md to staging_dir
    - Print output path to stdout (for piping to Phase 3)
    - Print summary to stderr: "Atom plan: N atomic notes + 1 MOC, M proposed new tags"

Add `if __name__ == "__main__": main()` guard.

Add module docstring: """atomize.py — Orchestrate Claude to convert parsed .docx JSON into atom plan JSON.\n\nUsage:\n    python3 scripts/atomize.py <parsed.json> [-o atom-plan.json] [--dry-run]"""
  </action>
  <verify>
1. `python3 -c "import ast; ast.parse(open('scripts/atomize.py').read()); print('SYNTAX OK')"` — no syntax errors
2. `python3 -c "from scripts.atomize import validate_atom_plan, validate_tags, validate_wikilinks; print('IMPORTS OK')"` — functions are importable (run from project root)
3. `python3 -c "from scripts.atomize import load_tags; tags = load_tags(); print(f'{len(tags)} tags loaded'); assert len(tags) >= 40"` — tags.yaml loading works
4. `python3 -c "from scripts.atomize import load_skill_md; s = load_skill_md(); print(f'SKILL.md: {len(s)} chars'); assert len(s) > 100"` — SKILL.md loading works
5. `python3 -c "from scripts.atomize import load_rules; a, t = load_rules(); print(f'atomization: {len(a)} chars, taxonomy: {len(t)} chars'); assert len(a) > 100 and len(t) > 100"` — rules loading works
6. `grep -c "def " scripts/atomize.py` — at least 10 function definitions
7. `grep "proposed-tags.md" scripts/atomize.py` — proposed-tags.md creation is present
8. `grep "dry.run\|dry_run" scripts/atomize.py` — dry-run flag is present
  </verify>
  <done>scripts/atomize.py exists with all helper functions (load_config, load_tags, load_skill_md, load_rules, assemble_prompt, call_claude, extract_json), validation functions (validate_atom_plan, validate_tags, validate_wikilinks), output functions (write_proposed_tags), and a main() with argparse supporting --dry-run. All functions importable without errors. Tags, rules, and SKILL.md load successfully from existing Phase 1 and Phase 2 artifacts.</done>
</task>

<task type="auto">
  <name>Task 2: Validate atomize.py with unit test on mock atom plan data</name>
  <files>scripts/atomize.py</files>
  <action>
Test the three validation functions with mock data to confirm they catch errors correctly. This does NOT require calling Claude — it tests the validation logic only.

Create a temporary test by running Python inline (no test file needed — validation is simple enough for inline checks):

1. **Test validate_atom_plan with valid data:**
   Create a mock atom plan dict with 2 atomic notes + 1 MOC, all required fields present, valid note_types, 3 tags each. Assert validate_atom_plan returns empty list.

2. **Test validate_atom_plan with missing fields:**
   Create a note missing "body" field. Assert error list is non-empty and mentions "missing fields".

3. **Test validate_atom_plan with wrong MOC count:**
   Create a plan with 0 MOCs. Assert error mentions "Expected exactly 1 MOC".
   Create a plan with 2 MOCs. Assert same error.

4. **Test validate_tags with non-canonical tag:**
   Load real tags from tags.yaml. Create a note with tag "fake/nonexistent". Assert validate_tags returns a warning about non-canonical tag.

5. **Test validate_tags with all valid tags:**
   Create notes using only real tags from tags.yaml. Assert validate_tags returns empty list.

6. **Test validate_wikilinks with orphaned link:**
   Create 2 notes. Note 1 body contains [[Note That Does Not Exist]]. Assert validate_wikilinks returns error about orphaned link.

7. **Test validate_wikilinks with valid links:**
   Create 2 notes where note 1 links to note 2 title and vice versa. Assert validate_wikilinks returns empty list.

8. **Test extract_json with code fences:**
   Test that extract_json('```json\n{"test": 1}\n```') returns {"test": 1}.
   Test that extract_json('{"test": 1}') returns {"test": 1} (no fences).

9. **Test --dry-run mode:**
   Run `python3 scripts/atomize.py <real_parsed_json> --dry-run` using one of the reference document parsed JSONs from /tmp/dw/staging/ (if available) or create a minimal test JSON. Verify it prints the assembled prompt to stdout and exits 0 without calling Claude. The prompt should contain SKILL.md content, rules content, tags list, and the document JSON.

If any test fails, fix the corresponding function in atomize.py before proceeding.

Note: Do NOT call Claude in these tests. The `call_claude` function is tested implicitly when the user runs the full pipeline. These tests validate the surrounding logic.
  </action>
  <verify>
All 9 test scenarios pass when run as inline Python assertions. Specifically:
1. `python3 -c "from scripts.atomize import validate_atom_plan; plan = {'notes': [{'id':'n1','title':'T1','note_type':'atomic','tags':['tech/ai','tech/llm'],'source_doc':'test.docx','date':'2026-01-01','body':'text','proposed_new_tags':[]},{'id':'n2','title':'T2','note_type':'atomic','tags':['tech/ai','tech/llm'],'source_doc':'test.docx','date':'2026-01-01','body':'text','proposed_new_tags':[]},{'id':'m1','title':'MOC','note_type':'moc','tags':['tech/ai','tech/llm'],'source_doc':'test.docx','date':'2026-01-01','body':'links','proposed_new_tags':[]}],'proposed_tags':[]}; errors = validate_atom_plan(plan); assert errors == [], f'Unexpected errors: {errors}'"` — valid plan passes
2. `python3 -c "from scripts.atomize import validate_wikilinks; plan = {'notes': [{'id':'n1','title':'Alpha','body':'See [[Beta]]','note_type':'atomic','tags':[],'source_doc':'','date':'','proposed_new_tags':[]},{'id':'n2','title':'Beta','body':'See [[Alpha]]','note_type':'atomic','tags':[],'source_doc':'','date':'','proposed_new_tags':[]}]}; errors = validate_wikilinks(plan); assert errors == [], f'Unexpected: {errors}'"` — valid wikilinks pass
3. `python3 -c "from scripts.atomize import validate_wikilinks; plan = {'notes': [{'id':'n1','title':'Alpha','body':'See [[Ghost]]','note_type':'atomic','tags':[],'source_doc':'','date':'','proposed_new_tags':[]}]}; errors = validate_wikilinks(plan); assert len(errors) > 0, 'Should catch orphaned link'"` — orphaned wikilink caught
4. `python3 -c "from scripts.atomize import extract_json; d = extract_json('\`\`\`json\n{\"test\": 1}\n\`\`\`'); assert d == {'test': 1}"` — code fence stripping works
  </verify>
  <done>All validation functions in atomize.py work correctly: validate_atom_plan catches missing fields, invalid note_types, wrong MOC count, and tag count violations; validate_tags identifies non-canonical tags; validate_wikilinks catches orphaned [[wikilinks]]; extract_json strips markdown code fences. The --dry-run flag prints the full assembled prompt without calling Claude.</done>
</task>

</tasks>

<verification>
1. scripts/atomize.py exists and has no syntax errors
2. atomize.py loads all Phase 1 artifacts (tags.yaml, rules/*.md) and Phase 2 SKILL.md without errors
3. validate_atom_plan catches: missing required fields, invalid note_type, wrong tag count, wrong MOC count
4. validate_tags identifies tags not in tags.yaml taxonomy
5. validate_wikilinks identifies [[wikilinks]] pointing to non-existent note titles
6. extract_json handles both raw JSON and code-fenced JSON responses
7. proposed-tags.md is always created (even when empty) — confirmed by write_proposed_tags logic
8. --dry-run prints assembled prompt without calling Claude
9. Output path printed to stdout for piping (Phase 3 integration)
10. MOC generation is confirmed last in SKILL.md processing steps (LINK-03, LINK-04)
</verification>

<success_criteria>
- atomize.py is a complete, runnable Python script that orchestrates Claude with SKILL.md to produce atom plan JSON
- All validation functions work correctly on mock data
- --dry-run mode works (prints prompt, exits 0)
- proposed-tags.md always created (prevents Phase 3 FileNotFoundError)
- All 10 Phase 2 requirements are addressed: DOCX-04/05 via SKILL.md processing steps, META-01/02/03/04 via tag assignment and frontmatter schema, LINK-01/02 via wikilink pass, LINK-03/04 via MOC generation
</success_criteria>

<output>
After completion, create `.planning/phases/02-ai-core/02-02-SUMMARY.md`
</output>
